{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, Dropout, MaxPool2D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "# TF extensions\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "# Python\n",
    "import os\n",
    "import json\n",
    "from functools import partial\n",
    "# Custom\n",
    "from utils import preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add before any TF calls - initializes the keras global outside of any tf.functions\n",
    "temp = tf.zeros([4, 32, 32, 3])\n",
    "preprocess_input(temp);\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    \"\"\"\n",
    "    Load an image from the file path and extract the label from the directory name\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = preprocess_input(img)\n",
    "    label = tf.strings.split(file_path, os.path.sep)[-3]\n",
    "    label = (label == 'stickie')\n",
    "    return img, label\n",
    "\n",
    "def read_dataset(path, batch_size=32):\n",
    "    \"\"\"\n",
    "    Read training dataset\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    dataset = tf.data.Dataset.list_files(os.path.join(path, '*/images/*.png'))\n",
    "    dataset = dataset.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    # Repeat, shuffle, batch and prefetch\n",
    "    dataset = dataset.repeat(None).shuffle(100).batch(batch_size).prefetch(AUTOTUNE)\n",
    "    \n",
    "    # Determine how many steps to run per epoch from the data description\n",
    "    data_split = path.strip('/').split('/')[-1]\n",
    "    data_description = json.load(open(os.path.join(path, '../DATA_DESCRIPTION.json')))\n",
    "    num_examples = data_description[data_split]\n",
    "    num_steps = num_examples // batch_size\n",
    "\n",
    "    return dataset, num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, None, None, 3), (None,)), types: (tf.float32, tf.bool)>,\n",
       " 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = '../data/processed/200428_092427/train/'\n",
    "read_dataset(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Hparams callbacks\n",
    "class HparamsMetricCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Metric callback for Hparams dashboard\n",
    "    Eager execution mode only (there might be a way to use @tf.function)\n",
    "    \"\"\"\n",
    "    def __init__(self, metric, log_dir):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        - metric - str - validation metric (should correspond to a metric used in `model.compile`)\n",
    "        - log_dir - str - log directory to store the metric (should be same dir as Tensorboard)\n",
    "        \n",
    "        Example:\n",
    "        ```\n",
    "        model.compile(..., metrics=['accuracy'])\n",
    "        tensorboard_cb = Tensorboard(log_dir=log_dir)\n",
    "        hparams_metric_cb = HparamsMetricCallback(metric='val_accuracy', log_dir=log_dir)\n",
    "        ```\n",
    "        \"\"\"\n",
    "        self.metric = metric\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        \"\"\"\n",
    "        This function will automatically be called during a model.fit() call\n",
    "        Creates a tf.summary from the validation metric stored in the training logs\n",
    "        \"\"\"\n",
    "        with tf.summary.create_file_writer(self.log_dir).as_default():\n",
    "            tf.summary.scalar(self.metric, logs[self.metric], epoch)\n",
    "\n",
    "            \n",
    "def create_hparams_callbacks(log_dir, opt_metric, hparams):\n",
    "    \"\"\"\n",
    "    Create the two callbacks necessary to use hparams in Tensorboard\n",
    "    \"\"\"\n",
    "    # Hparams metric callback to log the validation score\n",
    "    hparams_metric_cb = HparamsMetricCallback(\n",
    "        metric=opt_metric,\n",
    "        log_dir=log_dir\n",
    "    )\n",
    "    # Hparams callback to log the hyperparameter values\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams_config(\n",
    "            hparams=[hp.HParam(hparam)for hparam in hparams],\n",
    "            metrics=[hp.Metric(opt_metric)]\n",
    "        )\n",
    "    hparams_cb = hp.KerasCallback(\n",
    "        writer=log_dir,\n",
    "        hparams={hparam: args[hparam] for hparam in hparams}\n",
    "    )\n",
    "    return hparams_metric_cb, hparams_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args, metrics):\n",
    "    \"\"\"\n",
    "    Create trainable model initialised from VGG-16 pretrained on ImageNet\n",
    "    \"\"\"\n",
    "    # Pre-trained model\n",
    "    vgg = VGG16(weights='imagenet', input_tensor=Input(shape=(224,224,3)), include_top=False)\n",
    "    vgg.trainable = False\n",
    "    for layer in vgg.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Add trainable output layer\n",
    "    output = vgg.layers[-1].output\n",
    "    output = Dense(1, activation='sigmoid')(Flatten()(output))\n",
    "    model = Model(vgg.input, output)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=args['learning_rate']),\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_model({'learning_rate':0.1}, ['accuracy']).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    \"\"\"\n",
    "    Main training function\n",
    "    Training logs and model checkpoints will be stored in args['job_dir']\n",
    "\n",
    "    Arguments:\n",
    "    - args - dict - Training parameters.\n",
    "      Should contain:\n",
    "        - 'learning_rate'     - float - initial learning rate for training\n",
    "        - 'l2_regularisation' - float - regularisation used for dense (fully connected) layers\n",
    "        - 'batch_size'        - int   - mini-batch size used using training (Adam optimisation)\n",
    "        - 'epochs'            - int   - number of training epochs\n",
    "        - 'job_dir'           - str   - job directory used to store the logs and model checkpoints\n",
    "    \"\"\"\n",
    "    # Training parameters\n",
    "    metrics = ['accuracy']\n",
    "    opt_metric = 'val_accuracy'\n",
    "    hparams = ['learning_rate']\n",
    "    log_dir = os.path.join(args['job_dir'], 'training-logs')\n",
    "    model_dir = os.path.join(args['job_dir'], 'model-weights.tf')\n",
    "\n",
    "    # Model definition\n",
    "    model = get_model(args, metrics)\n",
    "\n",
    "    # Callback definition\n",
    "    tensorboard_cb = TensorBoard(\n",
    "        log_dir=log_dir\n",
    "    )\n",
    "    checkpoint_cb = ModelCheckpoint(\n",
    "        filepath=model_dir,\n",
    "        save_format='tf',\n",
    "        monitor=opt_metric,\n",
    "        mode='max',\n",
    "        save_freq='epoch',\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    hparams_metric_cb, hparams_cb = create_hparams_callbacks(log_dir, opt_metric, hparams)\n",
    "    callbacks = [tensorboard_cb, checkpoint_cb, hparams_metric_cb, hparams_cb]\n",
    "\n",
    "    # Load data\n",
    "    train_dir, val_dir = [os.path.join(args['data_dir'], split) for split in ['train', 'val']]\n",
    "    train_dataset, train_steps = read_dataset(train_dir, args['batch_size'])\n",
    "    val_dataset, val_steps = read_dataset(val_dir, args['batch_size'])\n",
    "\n",
    "    # Train model\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=int(args['epochs'] * args['epoch_split']),\n",
    "        steps_per_epoch=train_steps // args['epoch_split'],\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=3,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ../train-output  # remove logs from previous training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 5 steps, validate for 3 steps\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 35s 7s/step - loss: 1.0152 - accuracy: 0.4750 - val_loss: 1.1841 - val_accuracy: 0.4375\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.8683 - accuracy: 0.5125 - val_loss: 0.7807 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 34s 7s/step - loss: 0.7735 - accuracy: 0.4625 - val_loss: 0.6983 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.7332 - accuracy: 0.5000 - val_loss: 0.7183 - val_accuracy: 0.4375\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 34s 7s/step - loss: 0.6757 - accuracy: 0.6125 - val_loss: 0.7551 - val_accuracy: 0.4375\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.6987 - accuracy: 0.6250 - val_loss: 0.6996 - val_accuracy: 0.5417\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 38s 8s/step - loss: 0.7016 - accuracy: 0.5500 - val_loss: 0.7302 - val_accuracy: 0.5625\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.7167 - accuracy: 0.5875 - val_loss: 0.9352 - val_accuracy: 0.4375\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.7613 - accuracy: 0.5000 - val_loss: 0.7052 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 32s 6s/step - loss: 0.6897 - accuracy: 0.5250 - val_loss: 0.7497 - val_accuracy: 0.4167\n",
      "Train for 5 steps, validate for 3 steps\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 31s 6s/step - loss: 5.7655 - accuracy: 0.4875 - val_loss: 1.2323 - val_accuracy: 0.4583\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 39s 8s/step - loss: 3.2703 - accuracy: 0.4625 - val_loss: 4.2970 - val_accuracy: 0.5208\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 38s 8s/step - loss: 3.0345 - accuracy: 0.5500 - val_loss: 3.4036 - val_accuracy: 0.5417\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 32s 6s/step - loss: 2.4721 - accuracy: 0.5125 - val_loss: 1.4090 - val_accuracy: 0.6042\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 33s 7s/step - loss: 1.2737 - accuracy: 0.4750 - val_loss: 1.3144 - val_accuracy: 0.4375\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 34s 7s/step - loss: 0.9718 - accuracy: 0.4125 - val_loss: 0.6468 - val_accuracy: 0.6042\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.8733 - accuracy: 0.4875 - val_loss: 0.6209 - val_accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 34s 7s/step - loss: 1.1053 - accuracy: 0.5125 - val_loss: 0.9025 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.7501 - accuracy: 0.5625 - val_loss: 1.5089 - val_accuracy: 0.4167\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 33s 7s/step - loss: 1.3787 - accuracy: 0.4375 - val_loss: 1.5283 - val_accuracy: 0.5833\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in [0.001, 0.01]:\n",
    "    args = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': 16,\n",
    "        'epochs': 0.1,\n",
    "        'epoch_split': 100,  # split epoch to see training progress more frequently\n",
    "        'job_dir': '../train-output',\n",
    "        'data_dir': '../data/processed/200428_095708'\n",
    "    }\n",
    "\n",
    "    train_and_evaluate(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! poetry run tensorboard --logdir='train-output/training-logs'\n",
    "# ! tensorboard --logdir='../train-output/training-logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from utils import preview\n",
    "from imgaug import augmenters as iaa\n",
    "from math import ceil\n",
    "import IPython.display as display\n",
    "\n",
    "loaded=False  # Used as a flag to avoid reloading image data multiple times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load object images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_dir):\n",
    "    \"\"\"\n",
    "    Load transparent object images from a directory\n",
    "    \"\"\"\n",
    "    # Image file paths\n",
    "    image_files = os.listdir(image_dir)\n",
    "    image_files.remove('.DS_Store')\n",
    "    image_files = [os.path.join(image_dir, f) for f in image_files] \n",
    "\n",
    "    # Load images\n",
    "    images = []\n",
    "    for f in image_files:\n",
    "        img = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA)\n",
    "        images.append(img)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment object images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(img, padding=10):\n",
    "    \"\"\"\n",
    "    Pad the outer edges of a 2D image with a constant value\n",
    "    \n",
    "    Arguments:\n",
    "    - img - numpy array - image to pad\n",
    "    - padding - int - padding to apply\n",
    "    - constant - int - constant value to pad with\n",
    "    \n",
    "    Returns:\n",
    "    - image_padded - numpy array - padded image\n",
    "    \"\"\"\n",
    "    img = img.copy()\n",
    "    img_padded = np.zeros(\n",
    "        shape=(img.shape[0] + padding*2, img.shape[1] + padding*2, img.shape[2]),\n",
    "        dtype=img.dtype\n",
    "    )\n",
    "    img_padded[padding:-padding, padding:-padding] = img\n",
    "    return img_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarise_alpha(image, crop=False):\n",
    "    \"\"\"\n",
    "    Restores the alpha channel to 0 or 255 after image augmentation distorts it\n",
    "    \n",
    "    Arguments:\n",
    "    - image - numpy array - image to restore the alpha channel for\n",
    "    - crop - bool - whether to crop the image using the alpha channel\n",
    "    \n",
    "    Returns:\n",
    "    - image - numpy array - image with transparent background\n",
    "    \"\"\"\n",
    "    image = image.copy()\n",
    "    \n",
    "    # Binarise the alpha channel\n",
    "    alpha_channel = image[:, :, 3]\n",
    "    alpha_channel = (alpha_channel >= 128) * 255\n",
    "    image[:, :, 3] = alpha_channel\n",
    "    # Set all channels to 0 if alpha is 0 for that pixel\n",
    "    alpha_zero = (alpha_channel == 0)\n",
    "    image[alpha_zero] = 0\n",
    "\n",
    "    # Crop away any parts of the image that have 0 alpha\n",
    "    if crop:\n",
    "        object_pixels = np.where(~alpha_zero)\n",
    "        xmin, xmax = object_pixels[0].min(), object_pixels[0].max()\n",
    "        ymin, ymax = object_pixels[1].min(), object_pixels[1].max()\n",
    "        image = image[xmin:xmax, ymin:ymax]\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(images):\n",
    "    \"\"\"\n",
    "    Augment transparent object images using imgaug\n",
    "    \"\"\"\n",
    "    seq = iaa.Sequential(\n",
    "        [\n",
    "            # Horizontal flips\n",
    "            iaa.Fliplr(0.5),\n",
    "            # Small gaussian blur \n",
    "            iaa.Sometimes(\n",
    "                0.5,\n",
    "                iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "            ),\n",
    "            # Strengthen or weaken the contrast in each image.\n",
    "            iaa.LinearContrast((0.75, 1.5)),\n",
    "            # Add gaussian noise\n",
    "            iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "            # Scale/zoom and rotate\n",
    "            iaa.Affine(\n",
    "                scale={\"x\": (0.6, 1), \"y\": (0.6, 1)},\n",
    "                rotate=(-10, 10)\n",
    "            )\n",
    "        ],\n",
    "        random_order=True\n",
    "    )\n",
    "    \n",
    "    # Pad images, augment, binarize alpha channel and crop away transparent edges\n",
    "    images = [pad_image(img, padding=50) for img in images]\n",
    "    images_aug = seq(images=images)\n",
    "    images_aug = [binarise_alpha(img, crop=True) for img in images_aug]\n",
    "    \n",
    "    return images_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load texture images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_textures(texture_dir):\n",
    "    \"\"\"\n",
    "    Load texture images from the subdirectories of texture_dir\n",
    "    \"\"\"\n",
    "    # Texture image file paths\n",
    "    texture_folders = os.listdir(texture_dir)\n",
    "    texture_folders.remove('.DS_Store')\n",
    "\n",
    "    # Recursively get texture image file paths\n",
    "    texture_files = []\n",
    "    for folder in texture_folders:\n",
    "        folder_files = os.listdir(os.path.join(texture_dir, folder))\n",
    "        for file in folder_files:\n",
    "            if file != '.directory':\n",
    "                texture_files.append(os.path.join(texture_dir, folder, file))\n",
    "\n",
    "    # Load texture images\n",
    "    textures = []\n",
    "    for f in texture_files:    \n",
    "        img = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGBA)\n",
    "        textures.append(img)\n",
    "\n",
    "    return textures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training images from object and texture images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background(bg, obj, x, y, image_size):\n",
    "    \"\"\"\n",
    "    Add an object to a background at position x, y\n",
    "    The background will be resized to be square and a multiple of 32\n",
    "    x, y and the object size will be adjusted to fit the object on the background\n",
    "    \n",
    "    Arguments:\n",
    "    - obj - numpy array - object image to overlay on the background\n",
    "    - bg - numpy array - background image\n",
    "    - x - int - x coordinate for the top left of the image\n",
    "    - y - int - y coordinate for the top left of the image\n",
    "    - image_size - int - height and width of the output image (in pixels)\n",
    "    \n",
    "    Returns:\n",
    "    - img - numpy array - object image pasted onto the background image \n",
    "    - bbox - dict - bounding box for the object\n",
    "    \"\"\"\n",
    "    # Resize background to be of specified length\n",
    "    bg = bg.copy()\n",
    "    bg_height, bg_width = bg.shape[0], bg.shape[1]\n",
    "    if (bg_height < image_size) or (bg_width < image_size):\n",
    "        num_tiles = ceil(max(image_size/bg_height, image_size/bg_width))\n",
    "        bg = np.tile(bg, (num_tiles, num_tiles, 1))\n",
    "    bg = bg[:image_size, :image_size]\n",
    "    \n",
    "    # Initialise the default output\n",
    "    img = Image.fromarray(bg)\n",
    "    bbox = {'xmin': -1, 'xmax': -1, 'ymin': -1, 'ymax': -1}\n",
    "\n",
    "    # Paste object onto the background\n",
    "    if obj is not None:\n",
    "        obj = obj.copy()\n",
    "        # Resize the object so that it fits on the image\n",
    "        obj_height, obj_width = obj.shape[0], obj.shape[1]\n",
    "        while (obj_height >= image_size * 0.9) or (obj_width >= image_size * 0.9):\n",
    "            obj = obj[::2, ::2]\n",
    "            obj_height, obj_width = obj.shape[0], obj.shape[1]\n",
    "        # Paste the object onto the background\n",
    "        x = x % (image_size - obj_width)\n",
    "        y = y % (image_size - obj_height)\n",
    "        obj = Image.fromarray(obj)\n",
    "        img.paste(obj, (x, y), obj)\n",
    "        # Bounding box for object detection\n",
    "        bbox = {'xmin': x, 'xmax': x + obj_width, 'ymin': y, 'ymax': y + obj_height}\n",
    "\n",
    "    return img, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(backgrounds, objects=None, num_samples=1, image_size=224):\n",
    "    \"\"\"\n",
    "    Generate images from background and object images\n",
    "    If no object image is provided, the background image will simply be resized\n",
    "    \n",
    "    Arguments:\n",
    "    - backgrounds: list of background images\n",
    "    - objects: list of object images with transparent backgrounds\n",
    "    - num_samples: number of images to generate\n",
    "    \"\"\"\n",
    "    # Generate training images\n",
    "    for i in range(num_samples):\n",
    "        print(f'Progress: {i+1}/{num_samples}', end='\\r')\n",
    "        # Random sample (don't use np.random.choice, in case all images have same dimensions)\n",
    "        bg = backgrounds[np.random.randint(0, len(backgrounds)-1)]\n",
    "        if objects is not None:\n",
    "            obj = objects[np.random.randint(0, len(objects)-1)]\n",
    "            x = np.random.randint(0, bg.shape[1])\n",
    "            y = np.random.randint(0, bg.shape[0])\n",
    "        else:\n",
    "            obj = x = y = None\n",
    "        # Generate image - returns resized background image if obj is None\n",
    "        training_image, bbox = add_background(bg, obj, x, y, image_size)\n",
    "        yield training_image, bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save generated images as .tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def image_to_tfexample(image_raw, height, width, label, bbox):\n",
    "    \"\"\"Create a tf.Example object from an image\"\"\"\n",
    "    feature = {\n",
    "        'image_raw': bytes_feature(image_raw),\n",
    "        'height': int64_feature(height),\n",
    "        'width': int64_feature(width),\n",
    "        'label': bytes_feature(label),\n",
    "        'bbox': bytes_feature(bbox)\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(backgrounds, objects, num_samples, data_split, output_dir, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate and save images as .tfrecords\n",
    "        \n",
    "    Arguments:\n",
    "    - backgrounds: list of background images\n",
    "    - objects: list of object images with transparent backgrounds\n",
    "    - num_samples: total number of images to generate\n",
    "    - data_split: how to split num_samples across train/val/test splits\n",
    "    - output_dir: where to save the tfrecords\n",
    "    - **kwargs: will be passed to `generate_images` (image_size)\n",
    "    \"\"\"\n",
    "    # Calculate number of samples per dataset and save metadata in JSON file\n",
    "    sample_sizes = {\n",
    "        'train': int(num_samples * data_split[0]/100),\n",
    "        'val': int(num_samples * data_split[1]/100),\n",
    "        'test': int(num_samples * data_split[2]/100)\n",
    "    }\n",
    "    json.dump(sample_sizes, open(os.path.join(output_dir, 'DATA_DESCRIPTION.json'), 'w'))\n",
    "    \n",
    "    # Create a .tfrecord file per dataset\n",
    "    for dataset in ['train', 'val', 'test']:\n",
    "        print(f'\\nGenerating {dataset} data...')\n",
    "        samples_per_label = int(sample_sizes[dataset] / 2)\n",
    "\n",
    "        record_file = os.path.join(output_dir, f'{dataset}.tfrecord')\n",
    "        with tf.io.TFRecordWriter(record_file) as writer:\n",
    "            \n",
    "            # Generate and save positive examples (object pasted onto a background)\n",
    "            print(f'Generating {samples_per_label} positive training examples')\n",
    "            positive_images = generate_images(backgrounds, objects, samples_per_label, **kwargs)\n",
    "            for image, bbox in positive_images:\n",
    "                tf_example = image_to_tfexample(\n",
    "                    image_raw=image.tobytes(),\n",
    "                    height=224,\n",
    "                    width=224,\n",
    "                    label=b'stickie',\n",
    "                    bbox=json.dumps(bbox).encode()\n",
    "                )\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "            \n",
    "            # Generate and save negative examples (these just contain a background)\n",
    "            print(f'Generating {samples_per_label} negative training examples')\n",
    "            negative_images = generate_images(backgrounds, None, samples_per_label, **kwargs)\n",
    "            for image, bbox in negative_images:\n",
    "                tf_example = image_to_tfexample(\n",
    "                    image_raw=image.tobytes(),\n",
    "                    height=224,\n",
    "                    width=224,\n",
    "                    label=b'texture',\n",
    "                    bbox=json.dumps(bbox).encode()\n",
    "                )\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "        print(f\"Saved images to: '{record_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not loaded:\n",
    "    \n",
    "    # Load images\n",
    "    print('Loading object images...')\n",
    "    images = load_images('../data/interim/images/')\n",
    "    # Preview\n",
    "    for image in images[:2]:\n",
    "        preview(image, size=50)\n",
    "\n",
    "    # Augment images (twice, then append the original images)\n",
    "    print('Augmenting object images...')\n",
    "    images_aug = augment_images(images)\n",
    "    images_aug.extend(augment_images(images))\n",
    "    images_aug.extend(images)\n",
    "    # Preview\n",
    "    for image in images_aug[:2]:\n",
    "        preview(image, size=50)\n",
    "\n",
    "    # Load textures\n",
    "    print('Loading texture images...')\n",
    "    #    textures = load_textures('../data/raw/dtd/images/')\n",
    "    textures = [np.array((np.random.random((224,224,3)) * 255), dtype='uint8') for _ in range(100)]\n",
    "    # Preview\n",
    "    for texture in textures[:2]:\n",
    "        preview(texture, size=50)\n",
    "    \n",
    "    loaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images...\n",
      "\n",
      "Generating train data...\n",
      "Generating 4500 positive training examples\n",
      "Generating 4500 negative training examples\n",
      "Saved images to: '../data/processed/train.tfrecords'\n",
      "\n",
      "Generating val data...\n",
      "Generating 250 positive training examples\n",
      "Generating 250 negative training examples\n",
      "Saved images to: '../data/processed/val.tfrecords'\n",
      "\n",
      "Generating test data...\n",
      "Generating 250 positive training examples\n",
      "Generating 250 negative training examples\n",
      "Saved images to: '../data/processed/test.tfrecords'\n"
     ]
    }
   ],
   "source": [
    "# Generate images\n",
    "sample_size = 10000\n",
    "print('Generating images...')\n",
    "generate_and_save_images(textures, images_aug, sample_size, (90, 5, 5), '../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save records to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read saved record to test outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "raw_image_dataset = tf.data.TFRecordDataset('../data/processed/train.tfrecords')\n",
    "\n",
    "# image_feature_description = {\n",
    "#     'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "#     'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     'label': tf.io.FixedLenFeature([], tf.string)\n",
    "# }\n",
    "# def parse_image_function(tf_example):\n",
    "#     # Parse an input tf.Example proto using the \n",
    "#     return tf.io.parse_single_example(tf_example, image_feature_description)\n",
    "\n",
    "# parsed_image_dataset = raw_image_dataset.map(parse_image_function)\n",
    "# for example in parsed_image_dataset.take(2):\n",
    "#     display.display(Image.frombytes('RGB', (224, 224), example['image_raw'].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
